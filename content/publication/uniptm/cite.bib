@article {Meng2024.08.03.606471,
	author = {Meng, Lingkuan and Lin, Jiecong and Cheng, Ke and Xu, Kui and Sun, Hongyan and Wong, Ka-Chun},
	title = {UniPTM: Multiple PTM site prediction on full-length protein sequence},
	elocation-id = {2024.08.03.606471},
	year = {2024},
	doi = {10.1101/2024.08.03.606471},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Post-translational modifications (PTMs) enrich the functional diversity of proteins by attaching chemical groups to the side chains of amino acids. In recent years, a myr-iad of AI models have been proposed to predict many specific types of PTMs. However, those models typically adopt the sliding window approach to extract short and equal-length protein fragments from full-length proteins for model training. Unfortunately, such a subtle step results in the loss of long-range information from distal amino acids, which may impact the PTM formation process. In this study, we introduce UniPTM, a window-free model designed to train and test on natural and full-length protein sequences, enabling the prediction of multiple types of PTMs in a holistic manner. Moreover, we established PTMseq, the first comprehensive dataset of full-length pro-tein sequences with annotated PTMs, to train and validate our model. UniPTM has undergone extensive validations and significantly outperforms existing models, eluci-dating the influence of protein sequence completeness on PTM. Consequently, UniPTM offers interpretable and biologically meaningful predictions, enhancing our understand-ing of protein functionally and regulation. The source code and PTMseq dataset for UniPTM are available at https://www.github.com/TransPTM/UniPTM.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2024/08/06/2024.08.03.606471},
	eprint = {https://www.biorxiv.org/content/early/2024/08/06/2024.08.03.606471.full.pdf},
	journal = {bioRxiv}
}
